{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIXv5blL6dwL6ri7P5/CYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brohammad/VehicleDetection/blob/main/yolobased.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEmR3aDQxc7q"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install opencv-python-headless cvzone\n",
        "\n",
        "import cv2\n",
        "import pickle\n",
        "import cvzone\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load YOLOv3 model (make sure to upload the correct files)\n",
        "cfg_path = '/content/yolov3.cfg'\n",
        "weights_path = '/content/yolov3.weights'\n",
        "\n",
        "# Check if files exist\n",
        "assert os.path.exists(cfg_path), \"Config file not found\"\n",
        "assert os.path.exists(weights_path), \"Weights file not found\"\n",
        "\n",
        "# Load YOLOv3 model\n",
        "net = cv2.dnn.readNetFromDarknet(cfg_path, weights_path)\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "# Load the class labels\n",
        "with open(\"/content/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Load parking slot positions from file\n",
        "with open('/content/CarParkPos', 'rb') as f:\n",
        "    posList = pickle.load(f)\n",
        "\n",
        "# Define parking slot size\n",
        "width, height = 107, 48\n",
        "\n",
        "# Video capture\n",
        "cap = cv2.VideoCapture('/content/carPark.mp4')  # Replace with your video path\n",
        "\n",
        "# Function to check parking spaces\n",
        "def checkParkingSpace(imgPro):\n",
        "    spaceCounter = 0\n",
        "    for pos in posList:\n",
        "        x, y = pos\n",
        "        imgCrop = imgPro[y:y + height, x:x + width]\n",
        "        count = cv2.countNonZero(imgCrop)\n",
        "\n",
        "        color = (0, 255, 0) if count < 900 else (0, 0, 255)\n",
        "        thickness = 5 if count < 900 else 2\n",
        "        spaceCounter += (count < 900)\n",
        "\n",
        "        cv2.rectangle(img, pos, (pos[0] + width, pos[1] + height), color, thickness)\n",
        "        cvzone.putTextRect(img, str(count), (x, y + height - 3), scale=1,\n",
        "                           thickness=2, offset=0, colorR=color)\n",
        "\n",
        "    cvzone.putTextRect(img, f'Free: {spaceCounter}/{len(posList)}', (100, 50), scale=3,\n",
        "                           thickness=5, offset=20, colorR=(0, 200, 0))\n",
        "\n",
        "# Function to detect vehicles using YOLO\n",
        "def detect_vehicles(frame):\n",
        "    height, width, channels = frame.shape\n",
        "\n",
        "    # Prepare the frame for YOLO model (Blob conversion)\n",
        "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "\n",
        "    # Process YOLO model outputs\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:  # Confidence threshold\n",
        "                center_x = int(detection[0] * width)\n",
        "                center_y = int(detection[1] * height)\n",
        "                w = int(detection[2] * width)\n",
        "                h = int(detection[3] * height)\n",
        "\n",
        "                # Coordinates for rectangle\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Apply Non-maxima suppression to avoid multiple boxes\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    # Draw bounding boxes for detected vehicles\n",
        "    for i in range(len(boxes)):\n",
        "        if i in indices:\n",
        "            x, y, w, h = boxes[i]\n",
        "            label = str(classes[class_ids[i]])\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Process video and detect parking spaces\n",
        "frame_skip = 5  # Display every 5th frame\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "    if frame_count % frame_skip == 0:  # Only process selected frames\n",
        "        imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        imgBlur = cv2.GaussianBlur(imgGray, (3, 3), 1)\n",
        "        imgThreshold = cv2.adaptiveThreshold(imgBlur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                             cv2.THRESH_BINARY_INV, 25, 16)\n",
        "        imgMedian = cv2.medianBlur(imgThreshold, 5)\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        imgDilate = cv2.dilate(imgMedian, kernel, iterations=1)\n",
        "\n",
        "        # Detect vehicles in the frame using YOLO\n",
        "        img = detect_vehicles(img)\n",
        "\n",
        "        # Check parking space status\n",
        "        checkParkingSpace(imgDilate)\n",
        "\n",
        "        # Display the frame with parking slot overlay\n",
        "        cv2_imshow(img)\n",
        "\n",
        "        # Optional: Control frame rate with sleep\n",
        "        time.sleep(0.1)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ]
}